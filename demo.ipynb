{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cada113a-3eac-4cb0-8574-c945348c08f9",
   "metadata": {},
   "source": [
    "# Higgs uncertainty "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebbc5ec2-caa0-441c-bb3a-485517240b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 14:36:34.946500: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import h5py\n",
    "import importlib\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import yaml\n",
    "import common.datasets_hephy as datasets_hephy\n",
    "from data_loader.data_loader_2 import H5DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35309626-9b1b-45e3-ac70-7b0e2e03eecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"./demodir/models\"\n",
    "processes = ['htautau','ztautau','ttbar','diboson']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2353383-ed12-4784-aa24-9750aac61e34",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6402da91-6862-4fbc-bab5-2f305e57d73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FIXME: this part should download the data file from Zenodo \n",
    "training_data_dir = \"/scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/\"\n",
    "selection = \"lowMT_VBFJet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a7fde90-9077-4f6c-9ccd-549de1fe1893",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dl = datasets_hephy.get_data_loader(data_directory=training_data_dir, process=None, selection=selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf30fb9f-bda3-45b3-ad07-82f52fc5a4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FIXME: maybe we want to add some data plots here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232df95d-851c-444b-bad7-f8b3b89122ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b68b56-3805-41f1-b5ba-48df331f67aa",
   "metadata": {},
   "source": [
    "Training the models takes a long time. As a proof of concept, the examples below takes a small fraction of events and train the model for 1 epoch. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf923079-90a3-4b3f-a09e-47e3b853a623",
   "metadata": {},
   "source": [
    "### Inclusive Crosssection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f96b8d77-edee-48a1-9604-6bb68fbd300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ML.IC.IC import InclusiveCrosssection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e19dcd9-348f-417c-87b9-fd8b0ee7f057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing weight sums:   0%|                                                                        | 0/10 [00:04<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written ./demodir/models/IC/IC_lowMT_VBFJet.pkl\n",
      "Trained IC for this selection: lowMT_VBFJet\n",
      "IC: \u001b[1mlowMT_VBFJet\u001b[0m                           S/B = 0.003971  yield: htautau:    22.60 ztautau:  4120.57 ttbar:  1539.10 diboson:    32.14\n",
      "                                                           count: htautau:  1158182 ztautau:   412057 ttbar:   153883 diboson:     3213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ic_name = f\"IC_{selection}\"\n",
    "ic_model_directory = os.path.join( model_dir, \"IC\" )\n",
    "os.makedirs(ic_model_directory, exist_ok=True)\n",
    "filename = os.path.join(ic_model_directory, ic_name)+'.pkl'\n",
    "print (\"Training.\")\n",
    "ic = InclusiveCrosssection()\n",
    "\n",
    "ic.load_training_data(datasets_hephy, training_data_dir, selection)\n",
    "#ic.train             (datasets_hephy, mva_selections.selections[args.mvaSelection] if args.mvaSelection is not None else None, small=True)\n",
    "ic.train             (datasets_hephy, None, small=True)\n",
    "\n",
    "ic.save(filename)\n",
    "print (\"Written %s\"%( filename ))\n",
    "\n",
    "print(f\"Trained IC for this selection: {selection}\")\n",
    "print(ic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffd2b34-f0ee-423c-a873-0799c681b9f3",
   "metadata": {},
   "source": [
    "### Scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc1160fa-5677-418e-b7b2-3d0e0cba30d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature mean/variance:   0%|                                                              | 0/10 [00:05<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written ./demodir/models/Scaler/Scaler_lowMT_VBFJet.pkl\n",
      "Training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature mean/variance:   0%|                                                              | 0/10 [00:05<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written ./demodir/models/Scaler/Scaler_htautau_lowMT_VBFJet.pkl\n",
      "Training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature mean/variance:   0%|                                                              | 0/10 [00:02<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written ./demodir/models/Scaler/Scaler_ztautau_lowMT_VBFJet.pkl\n",
      "Training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature mean/variance:   0%|                                                              | 0/10 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written ./demodir/models/Scaler/Scaler_ttbar_lowMT_VBFJet.pkl\n",
      "Training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature mean/variance:   0%|                                                              | 0/10 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written ./demodir/models/Scaler/Scaler_diboson_lowMT_VBFJet.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from ML.Scaler.Scaler import Scaler\n",
    "scalar_model_directory = os.path.join(model_dir, \"Scaler\")\n",
    "os.makedirs(scalar_model_directory, exist_ok=True)\n",
    "process_to_train = [None]+processes\n",
    "for p in process_to_train:\n",
    "    subdirs = [arg for arg in [p, selection] if arg is not None]\n",
    "    scaler_name = \"Scaler_\"+\"_\".join(subdirs)\n",
    "    filename = os.path.join(scalar_model_directory, scaler_name) + '.pkl'\n",
    "    print(\"Training.\")\n",
    "    scaler = Scaler()\n",
    "\n",
    "    scaler.load_training_data(training_data_dir=training_data_dir, datasets_hephy=datasets_hephy, selection=selection, process=p)\n",
    "    scaler.train(small=True)\n",
    "\n",
    "    scaler.save(filename)\n",
    "    print(f\"Written {filename}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c63a0b-fd18-4de9-90e1-4296f80e0c66",
   "metadata": {},
   "source": [
    "### Inclusive Crosssection Parametrization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e824375c-b313-4ff2-897f-2cc7546bc96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ML.ICP.ICP import InclusiveCrosssectionParametrization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8affa901-a184-4cc9-a3d2-10eeec2431ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training.\n",
      "ICP training data: Base point nu = (0.0, 0.0, 0.0), alpha = (1.0, 1.0, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/htautau.h5\n",
      "ICP training data: Base point nu = (-3.0, 0.0, 0.0), alpha = (0.97, 1.0, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/htautau_tes_0p97.h5\n",
      "ICP training data: Base point nu = (-2.0, 0.0, 0.0), alpha = (0.98, 1.0, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/htautau_tes_0p98.h5\n",
      "ICP training data: Base point nu = (-1.0, -1.0, 0.0), alpha = (0.99, 0.99, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/htautau_tes_0p99_jes_0p99.h5\n",
      "ICP training data: Base point nu = (-1.0, -1.0, 1.0), alpha = (0.99, 0.99, 1.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/htautau_tes_0p99_jes_0p99_met_1.h5\n",
      "ICP training data: Base point nu = (-1.0, -1.0, 2.0), alpha = (0.99, 0.99, 2.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/htautau_tes_0p99_jes_0p99_met_2.h5\n",
      "ICP training data: Base point nu = (-1.0, 0.0, 0.0), alpha = (0.99, 1.0, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/htautau_tes_0p99.h5\n",
      "ICP training data: Base point nu = (-1.0, 0.0, 1.0), alpha = (0.99, 1.0, 1.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/htautau_tes_0p99_met_1.h5\n",
      "ICP training data: Base point nu = (-1.0, 0.0, 2.0), alpha = (0.99, 1.0, 2.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/htautau_tes_0p99_met_2.h5\n",
      "ICP training data: Base point nu = (-1.0, 1.0, 0.0), alpha = (0.99, 1.01, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/htautau_tes_0p99_jes_1p01.h5\n",
      "ICP training data: Base point nu = (-1.0, 1.0, 1.0), alpha = (0.99, 1.01, 1.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/htautau_tes_0p99_jes_1p01_met_1.h5\n",
      "ICP training data: Base point nu = (-1.0, 1.0, 2.0), alpha = (0.99, 1.01, 2.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/htautau_tes_0p99_jes_1p01_met_2.h5\n",
      "ICP training data: Base point nu = (0.0, -3.0, 0.0), alpha = (1.0, 0.97, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/htautau_jes_0p97.h5\n",
      "ICP training data: Base point nu = (0.0, -2.0, 0.0), alpha = (1.0, 0.98, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/htautau_jes_0p98.h5\n",
      "ICP training data: Base point nu = (0.0, -1.0, 0.0), alpha = (1.0, 0.99, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/htautau_jes_0p99.h5\n",
      "ICP training data: Base point nu = (0.0, -1.0, 1.0), alpha = (1.0, 0.99, 1.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/htautau_jes_0p99_met_1.h5\n",
      "ICP training data: Base point nu = (0.0, -1.0, 2.0), alpha = (1.0, 0.99, 2.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/htautau_jes_0p99_met_2.h5\n",
      "ICP training data: Base point nu = (0.0, 0.0, 1.0), alpha = (1.0, 1.0, 1.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/htautau_met_1.h5\n",
      "ICP training data: Base point nu = (0.0, 0.0, 2.0), alpha = (1.0, 1.0, 2.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/htautau_met_2.h5\n",
      "ICP training data: Base point nu = (0.0, 1.0, 0.0), alpha = (1.0, 1.01, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/htautau_jes_1p01.h5\n",
      "ICP training data: Base point nu = (0.0, 1.0, 1.0), alpha = (1.0, 1.01, 1.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/htautau_jes_1p01_met_1.h5\n",
      "ICP training data: Base point nu = (0.0, 1.0, 2.0), alpha = (1.0, 1.01, 2.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/htautau_jes_1p01_met_2.h5\n",
      "ICP training data: Base point nu = (0.0, 2.0, 0.0), alpha = (1.0, 1.02, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/htautau_jes_1p02.h5\n",
      "ICP training data: Base point nu = (0.0, 3.0, 0.0), alpha = (1.0, 1.03, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/htautau_jes_1p03.h5\n",
      "ICP training data: Base point nu = (1.0, -1.0, 0.0), alpha = (1.01, 0.99, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/htautau_tes_1p01_jes_0p99.h5\n",
      "ICP training data: Base point nu = (1.0, -1.0, 1.0), alpha = (1.01, 0.99, 1.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/htautau_tes_1p01_jes_0p99_met_1.h5\n",
      "ICP training data: Base point nu = (1.0, -1.0, 2.0), alpha = (1.01, 0.99, 2.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/htautau_tes_1p01_jes_0p99_met_2.h5\n",
      "ICP training data: Base point nu = (1.0, 0.0, 0.0), alpha = (1.01, 1.0, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/htautau_tes_1p01.h5\n",
      "ICP training data: Base point nu = (1.0, 0.0, 1.0), alpha = (1.01, 1.0, 1.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/htautau_tes_1p01_met_1.h5\n",
      "ICP training data: Base point nu = (1.0, 0.0, 2.0), alpha = (1.01, 1.0, 2.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/htautau_tes_1p01_met_2.h5\n",
      "ICP training data: Base point nu = (1.0, 1.0, 0.0), alpha = (1.01, 1.01, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/htautau_tes_1p01_jes_1p01.h5\n",
      "ICP training data: Base point nu = (1.0, 1.0, 1.0), alpha = (1.01, 1.01, 1.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/htautau_tes_1p01_jes_1p01_met_1.h5\n",
      "ICP training data: Base point nu = (1.0, 1.0, 2.0), alpha = (1.01, 1.01, 2.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/htautau_tes_1p01_jes_1p01_met_2.h5\n",
      "ICP training data: Base point nu = (2.0, 0.0, 0.0), alpha = (1.02, 1.0, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/htautau_tes_1p02.h5\n",
      "ICP training data: Base point nu = (3.0, 0.0, 0.0), alpha = (1.03, 1.0, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/htautau_tes_1p03.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing weight sum:   0%|                                                                         | 0/10 [00:05<?, ?batch/s]\n",
      "Computing weight sum:   0%|                                                                         | 0/10 [00:04<?, ?batch/s]\n",
      "Computing weight sum:   0%|                                                                         | 0/10 [00:05<?, ?batch/s]\n",
      "Computing weight sum:   0%|                                                                         | 0/10 [00:04<?, ?batch/s]\n",
      "Computing weight sum:   0%|                                                                         | 0/10 [00:04<?, ?batch/s]\n",
      "Computing weight sum:   0%|                                                                         | 0/10 [00:04<?, ?batch/s]\n",
      "Computing weight sum:   0%|                                                                         | 0/10 [00:05<?, ?batch/s]\n",
      "Computing weight sum:   0%|                                                                         | 0/10 [00:05<?, ?batch/s]\n",
      "Computing weight sum:   0%|                                                                         | 0/10 [00:05<?, ?batch/s]\n",
      "Computing weight sum:   0%|                                                                         | 0/10 [00:05<?, ?batch/s]\n",
      "Computing weight sum:   0%|                                                                         | 0/10 [00:05<?, ?batch/s]\n",
      "Computing weight sum:   0%|                                                                         | 0/10 [00:05<?, ?batch/s]\n",
      "Computing weight sum:   0%|                                                                         | 0/10 [00:04<?, ?batch/s]\n",
      "Computing weight sum:   0%|                                                                         | 0/10 [00:05<?, ?batch/s]\n",
      "Computing weight sum:   0%|                                                                         | 0/10 [00:05<?, ?batch/s]\n",
      "Computing weight sum:   0%|                                                                         | 0/10 [00:05<?, ?batch/s]\n",
      "Computing weight sum:   0%|                                                                         | 0/10 [00:05<?, ?batch/s]\n",
      "Computing weight sum:   0%|                                                                         | 0/10 [00:05<?, ?batch/s]\n",
      "Computing weight sum:   0%|                                                                         | 0/10 [00:05<?, ?batch/s]\n",
      "Computing weight sum:   0%|                                                                         | 0/10 [00:04<?, ?batch/s]\n",
      "Computing weight sum:   0%|                                                                         | 0/10 [00:04<?, ?batch/s]\n",
      "Computing weight sum:   0%|                                                                         | 0/10 [00:04<?, ?batch/s]\n",
      "Computing weight sum:   0%|                                                                         | 0/10 [00:05<?, ?batch/s]\n",
      "Computing weight sum:   0%|                                                                         | 0/10 [00:05<?, ?batch/s]\n",
      "Computing weight sum:   0%|                                                                         | 0/10 [00:05<?, ?batch/s]\n",
      "Computing weight sum:   0%|                                                                         | 0/10 [00:04<?, ?batch/s]\n",
      "Computing weight sum:   0%|                                                                         | 0/10 [00:05<?, ?batch/s]\n",
      "Computing weight sum:   0%|                                                                         | 0/10 [00:04<?, ?batch/s]\n",
      "Computing weight sum:   0%|                                                                         | 0/10 [00:05<?, ?batch/s]\n",
      "Computing weight sum:   0%|                                                                         | 0/10 [00:04<?, ?batch/s]\n",
      "Computing weight sum:   0%|                                                                         | 0/10 [00:05<?, ?batch/s]\n",
      "Computing weight sum:   0%|                                                                         | 0/10 [00:05<?, ?batch/s]\n",
      "Computing weight sum:   0%|                                                                         | 0/10 [00:05<?, ?batch/s]\n",
      "Computing weight sum:   0%|                                                                         | 0/10 [00:05<?, ?batch/s]\n",
      "Computing weight sum:   0%|                                                                         | 0/10 [00:05<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written ./demodir/models/ICP/ICP_htautau_lowMT_VBFJet_icp_quad_tes_jes_met.pkl\n",
      "Trained ICP with config ML.configs.icp_quad_tes_jes_met in selection lowMT_VBFJet\n",
      "ICP: lowMT_VBFJet                                 +6.0e-03*nu_tes +1.3e-02*nu_jes -3.4e-05*nu_met -9.9e-05*nu_tes*nu_tes -1.6e-04*nu_jes*nu_jes -9.2e-05*nu_met*nu_met +4.6e-05*nu_tes*nu_jes -4.5e-06*nu_tes*nu_met +5.2e-06*nu_jes*nu_met\n",
      "Training.\n",
      "ICP training data: Base point nu = (0.0, 0.0, 0.0), alpha = (1.0, 1.0, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ztautau.h5\n",
      "ICP training data: Base point nu = (-3.0, 0.0, 0.0), alpha = (0.97, 1.0, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ztautau_tes_0p97.h5\n",
      "ICP training data: Base point nu = (-2.0, 0.0, 0.0), alpha = (0.98, 1.0, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ztautau_tes_0p98.h5\n",
      "ICP training data: Base point nu = (-1.0, -1.0, 0.0), alpha = (0.99, 0.99, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ztautau_tes_0p99_jes_0p99.h5\n",
      "ICP training data: Base point nu = (-1.0, -1.0, 1.0), alpha = (0.99, 0.99, 1.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ztautau_tes_0p99_jes_0p99_met_1.h5\n",
      "ICP training data: Base point nu = (-1.0, -1.0, 2.0), alpha = (0.99, 0.99, 2.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ztautau_tes_0p99_jes_0p99_met_2.h5\n",
      "ICP training data: Base point nu = (-1.0, 0.0, 0.0), alpha = (0.99, 1.0, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ztautau_tes_0p99.h5\n",
      "ICP training data: Base point nu = (-1.0, 0.0, 1.0), alpha = (0.99, 1.0, 1.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ztautau_tes_0p99_met_1.h5\n",
      "ICP training data: Base point nu = (-1.0, 0.0, 2.0), alpha = (0.99, 1.0, 2.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ztautau_tes_0p99_met_2.h5\n",
      "ICP training data: Base point nu = (-1.0, 1.0, 0.0), alpha = (0.99, 1.01, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ztautau_tes_0p99_jes_1p01.h5\n",
      "ICP training data: Base point nu = (-1.0, 1.0, 1.0), alpha = (0.99, 1.01, 1.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ztautau_tes_0p99_jes_1p01_met_1.h5\n",
      "ICP training data: Base point nu = (-1.0, 1.0, 2.0), alpha = (0.99, 1.01, 2.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ztautau_tes_0p99_jes_1p01_met_2.h5\n",
      "ICP training data: Base point nu = (0.0, -3.0, 0.0), alpha = (1.0, 0.97, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ztautau_jes_0p97.h5\n",
      "ICP training data: Base point nu = (0.0, -2.0, 0.0), alpha = (1.0, 0.98, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ztautau_jes_0p98.h5\n",
      "ICP training data: Base point nu = (0.0, -1.0, 0.0), alpha = (1.0, 0.99, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ztautau_jes_0p99.h5\n",
      "ICP training data: Base point nu = (0.0, -1.0, 1.0), alpha = (1.0, 0.99, 1.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ztautau_jes_0p99_met_1.h5\n",
      "ICP training data: Base point nu = (0.0, -1.0, 2.0), alpha = (1.0, 0.99, 2.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ztautau_jes_0p99_met_2.h5\n",
      "ICP training data: Base point nu = (0.0, 0.0, 1.0), alpha = (1.0, 1.0, 1.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ztautau_met_1.h5\n",
      "ICP training data: Base point nu = (0.0, 0.0, 2.0), alpha = (1.0, 1.0, 2.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ztautau_met_2.h5\n",
      "ICP training data: Base point nu = (0.0, 1.0, 0.0), alpha = (1.0, 1.01, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ztautau_jes_1p01.h5\n",
      "ICP training data: Base point nu = (0.0, 1.0, 1.0), alpha = (1.0, 1.01, 1.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ztautau_jes_1p01_met_1.h5\n",
      "ICP training data: Base point nu = (0.0, 1.0, 2.0), alpha = (1.0, 1.01, 2.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ztautau_jes_1p01_met_2.h5\n",
      "ICP training data: Base point nu = (0.0, 2.0, 0.0), alpha = (1.0, 1.02, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ztautau_jes_1p02.h5\n",
      "ICP training data: Base point nu = (0.0, 3.0, 0.0), alpha = (1.0, 1.03, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ztautau_jes_1p03.h5\n",
      "ICP training data: Base point nu = (1.0, -1.0, 0.0), alpha = (1.01, 0.99, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ztautau_tes_1p01_jes_0p99.h5\n",
      "ICP training data: Base point nu = (1.0, -1.0, 1.0), alpha = (1.01, 0.99, 1.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ztautau_tes_1p01_jes_0p99_met_1.h5\n",
      "ICP training data: Base point nu = (1.0, -1.0, 2.0), alpha = (1.01, 0.99, 2.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ztautau_tes_1p01_jes_0p99_met_2.h5\n",
      "ICP training data: Base point nu = (1.0, 0.0, 0.0), alpha = (1.01, 1.0, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ztautau_tes_1p01.h5\n",
      "ICP training data: Base point nu = (1.0, 0.0, 1.0), alpha = (1.01, 1.0, 1.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ztautau_tes_1p01_met_1.h5\n",
      "ICP training data: Base point nu = (1.0, 0.0, 2.0), alpha = (1.01, 1.0, 2.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ztautau_tes_1p01_met_2.h5\n",
      "ICP training data: Base point nu = (1.0, 1.0, 0.0), alpha = (1.01, 1.01, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ztautau_tes_1p01_jes_1p01.h5\n",
      "ICP training data: Base point nu = (1.0, 1.0, 1.0), alpha = (1.01, 1.01, 1.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ztautau_tes_1p01_jes_1p01_met_1.h5\n",
      "ICP training data: Base point nu = (1.0, 1.0, 2.0), alpha = (1.01, 1.01, 2.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ztautau_tes_1p01_jes_1p01_met_2.h5\n",
      "ICP training data: Base point nu = (2.0, 0.0, 0.0), alpha = (1.02, 1.0, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ztautau_tes_1p02.h5\n",
      "ICP training data: Base point nu = (3.0, 0.0, 0.0), alpha = (1.03, 1.0, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ztautau_tes_1p03.h5\n",
      "Written ./demodir/models/ICP/ICP_ztautau_lowMT_VBFJet_icp_quad_tes_jes_met.pkl\n",
      "Trained ICP with config ML.configs.icp_quad_tes_jes_met in selection lowMT_VBFJet\n",
      "ICP: lowMT_VBFJet                                 +6.0e-03*nu_tes +1.3e-02*nu_jes -3.4e-05*nu_met -9.9e-05*nu_tes*nu_tes -1.6e-04*nu_jes*nu_jes -9.2e-05*nu_met*nu_met +4.6e-05*nu_tes*nu_jes -4.5e-06*nu_tes*nu_met +5.2e-06*nu_jes*nu_met\n",
      "Training.\n",
      "ICP training data: Base point nu = (0.0, 0.0, 0.0), alpha = (1.0, 1.0, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ttbar.h5\n",
      "ICP training data: Base point nu = (-3.0, 0.0, 0.0), alpha = (0.97, 1.0, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ttbar_tes_0p97.h5\n",
      "ICP training data: Base point nu = (-2.0, 0.0, 0.0), alpha = (0.98, 1.0, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ttbar_tes_0p98.h5\n",
      "ICP training data: Base point nu = (-1.0, -1.0, 0.0), alpha = (0.99, 0.99, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ttbar_tes_0p99_jes_0p99.h5\n",
      "ICP training data: Base point nu = (-1.0, -1.0, 1.0), alpha = (0.99, 0.99, 1.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ttbar_tes_0p99_jes_0p99_met_1.h5\n",
      "ICP training data: Base point nu = (-1.0, -1.0, 2.0), alpha = (0.99, 0.99, 2.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ttbar_tes_0p99_jes_0p99_met_2.h5\n",
      "ICP training data: Base point nu = (-1.0, 0.0, 0.0), alpha = (0.99, 1.0, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ttbar_tes_0p99.h5\n",
      "ICP training data: Base point nu = (-1.0, 0.0, 1.0), alpha = (0.99, 1.0, 1.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ttbar_tes_0p99_met_1.h5\n",
      "ICP training data: Base point nu = (-1.0, 0.0, 2.0), alpha = (0.99, 1.0, 2.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ttbar_tes_0p99_met_2.h5\n",
      "ICP training data: Base point nu = (-1.0, 1.0, 0.0), alpha = (0.99, 1.01, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ttbar_tes_0p99_jes_1p01.h5\n",
      "ICP training data: Base point nu = (-1.0, 1.0, 1.0), alpha = (0.99, 1.01, 1.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ttbar_tes_0p99_jes_1p01_met_1.h5\n",
      "ICP training data: Base point nu = (-1.0, 1.0, 2.0), alpha = (0.99, 1.01, 2.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ttbar_tes_0p99_jes_1p01_met_2.h5\n",
      "ICP training data: Base point nu = (0.0, -3.0, 0.0), alpha = (1.0, 0.97, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ttbar_jes_0p97.h5\n",
      "ICP training data: Base point nu = (0.0, -2.0, 0.0), alpha = (1.0, 0.98, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ttbar_jes_0p98.h5\n",
      "ICP training data: Base point nu = (0.0, -1.0, 0.0), alpha = (1.0, 0.99, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ttbar_jes_0p99.h5\n",
      "ICP training data: Base point nu = (0.0, -1.0, 1.0), alpha = (1.0, 0.99, 1.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ttbar_jes_0p99_met_1.h5\n",
      "ICP training data: Base point nu = (0.0, -1.0, 2.0), alpha = (1.0, 0.99, 2.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ttbar_jes_0p99_met_2.h5\n",
      "ICP training data: Base point nu = (0.0, 0.0, 1.0), alpha = (1.0, 1.0, 1.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ttbar_met_1.h5\n",
      "ICP training data: Base point nu = (0.0, 0.0, 2.0), alpha = (1.0, 1.0, 2.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ttbar_met_2.h5\n",
      "ICP training data: Base point nu = (0.0, 1.0, 0.0), alpha = (1.0, 1.01, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ttbar_jes_1p01.h5\n",
      "ICP training data: Base point nu = (0.0, 1.0, 1.0), alpha = (1.0, 1.01, 1.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ttbar_jes_1p01_met_1.h5\n",
      "ICP training data: Base point nu = (0.0, 1.0, 2.0), alpha = (1.0, 1.01, 2.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ttbar_jes_1p01_met_2.h5\n",
      "ICP training data: Base point nu = (0.0, 2.0, 0.0), alpha = (1.0, 1.02, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ttbar_jes_1p02.h5\n",
      "ICP training data: Base point nu = (0.0, 3.0, 0.0), alpha = (1.0, 1.03, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ttbar_jes_1p03.h5\n",
      "ICP training data: Base point nu = (1.0, -1.0, 0.0), alpha = (1.01, 0.99, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ttbar_tes_1p01_jes_0p99.h5\n",
      "ICP training data: Base point nu = (1.0, -1.0, 1.0), alpha = (1.01, 0.99, 1.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ttbar_tes_1p01_jes_0p99_met_1.h5\n",
      "ICP training data: Base point nu = (1.0, -1.0, 2.0), alpha = (1.01, 0.99, 2.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ttbar_tes_1p01_jes_0p99_met_2.h5\n",
      "ICP training data: Base point nu = (1.0, 0.0, 0.0), alpha = (1.01, 1.0, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ttbar_tes_1p01.h5\n",
      "ICP training data: Base point nu = (1.0, 0.0, 1.0), alpha = (1.01, 1.0, 1.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ttbar_tes_1p01_met_1.h5\n",
      "ICP training data: Base point nu = (1.0, 0.0, 2.0), alpha = (1.01, 1.0, 2.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ttbar_tes_1p01_met_2.h5\n",
      "ICP training data: Base point nu = (1.0, 1.0, 0.0), alpha = (1.01, 1.01, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ttbar_tes_1p01_jes_1p01.h5\n",
      "ICP training data: Base point nu = (1.0, 1.0, 1.0), alpha = (1.01, 1.01, 1.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ttbar_tes_1p01_jes_1p01_met_1.h5\n",
      "ICP training data: Base point nu = (1.0, 1.0, 2.0), alpha = (1.01, 1.01, 2.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ttbar_tes_1p01_jes_1p01_met_2.h5\n",
      "ICP training data: Base point nu = (2.0, 0.0, 0.0), alpha = (1.02, 1.0, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ttbar_tes_1p02.h5\n",
      "ICP training data: Base point nu = (3.0, 0.0, 0.0), alpha = (1.03, 1.0, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/ttbar_tes_1p03.h5\n",
      "Written ./demodir/models/ICP/ICP_ttbar_lowMT_VBFJet_icp_quad_tes_jes_met.pkl\n",
      "Trained ICP with config ML.configs.icp_quad_tes_jes_met in selection lowMT_VBFJet\n",
      "ICP: lowMT_VBFJet                                 +6.0e-03*nu_tes +1.3e-02*nu_jes -3.4e-05*nu_met -9.9e-05*nu_tes*nu_tes -1.6e-04*nu_jes*nu_jes -9.2e-05*nu_met*nu_met +4.6e-05*nu_tes*nu_jes -4.5e-06*nu_tes*nu_met +5.2e-06*nu_jes*nu_met\n",
      "Training.\n",
      "ICP training data: Base point nu = (0.0, 0.0, 0.0), alpha = (1.0, 1.0, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/diboson.h5\n",
      "ICP training data: Base point nu = (-3.0, 0.0, 0.0), alpha = (0.97, 1.0, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/diboson_tes_0p97.h5\n",
      "ICP training data: Base point nu = (-2.0, 0.0, 0.0), alpha = (0.98, 1.0, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/diboson_tes_0p98.h5\n",
      "ICP training data: Base point nu = (-1.0, -1.0, 0.0), alpha = (0.99, 0.99, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/diboson_tes_0p99_jes_0p99.h5\n",
      "ICP training data: Base point nu = (-1.0, -1.0, 1.0), alpha = (0.99, 0.99, 1.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/diboson_tes_0p99_jes_0p99_met_1.h5\n",
      "ICP training data: Base point nu = (-1.0, -1.0, 2.0), alpha = (0.99, 0.99, 2.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/diboson_tes_0p99_jes_0p99_met_2.h5\n",
      "ICP training data: Base point nu = (-1.0, 0.0, 0.0), alpha = (0.99, 1.0, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/diboson_tes_0p99.h5\n",
      "ICP training data: Base point nu = (-1.0, 0.0, 1.0), alpha = (0.99, 1.0, 1.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/diboson_tes_0p99_met_1.h5\n",
      "ICP training data: Base point nu = (-1.0, 0.0, 2.0), alpha = (0.99, 1.0, 2.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/diboson_tes_0p99_met_2.h5\n",
      "ICP training data: Base point nu = (-1.0, 1.0, 0.0), alpha = (0.99, 1.01, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/diboson_tes_0p99_jes_1p01.h5\n",
      "ICP training data: Base point nu = (-1.0, 1.0, 1.0), alpha = (0.99, 1.01, 1.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/diboson_tes_0p99_jes_1p01_met_1.h5\n",
      "ICP training data: Base point nu = (-1.0, 1.0, 2.0), alpha = (0.99, 1.01, 2.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/diboson_tes_0p99_jes_1p01_met_2.h5\n",
      "ICP training data: Base point nu = (0.0, -3.0, 0.0), alpha = (1.0, 0.97, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/diboson_jes_0p97.h5\n",
      "ICP training data: Base point nu = (0.0, -2.0, 0.0), alpha = (1.0, 0.98, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/diboson_jes_0p98.h5\n",
      "ICP training data: Base point nu = (0.0, -1.0, 0.0), alpha = (1.0, 0.99, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/diboson_jes_0p99.h5\n",
      "ICP training data: Base point nu = (0.0, -1.0, 1.0), alpha = (1.0, 0.99, 1.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/diboson_jes_0p99_met_1.h5\n",
      "ICP training data: Base point nu = (0.0, -1.0, 2.0), alpha = (1.0, 0.99, 2.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/diboson_jes_0p99_met_2.h5\n",
      "ICP training data: Base point nu = (0.0, 0.0, 1.0), alpha = (1.0, 1.0, 1.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/diboson_met_1.h5\n",
      "ICP training data: Base point nu = (0.0, 0.0, 2.0), alpha = (1.0, 1.0, 2.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/diboson_met_2.h5\n",
      "ICP training data: Base point nu = (0.0, 1.0, 0.0), alpha = (1.0, 1.01, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/diboson_jes_1p01.h5\n",
      "ICP training data: Base point nu = (0.0, 1.0, 1.0), alpha = (1.0, 1.01, 1.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/diboson_jes_1p01_met_1.h5\n",
      "ICP training data: Base point nu = (0.0, 1.0, 2.0), alpha = (1.0, 1.01, 2.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/diboson_jes_1p01_met_2.h5\n",
      "ICP training data: Base point nu = (0.0, 2.0, 0.0), alpha = (1.0, 1.02, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/diboson_jes_1p02.h5\n",
      "ICP training data: Base point nu = (0.0, 3.0, 0.0), alpha = (1.0, 1.03, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/diboson_jes_1p03.h5\n",
      "ICP training data: Base point nu = (1.0, -1.0, 0.0), alpha = (1.01, 0.99, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/diboson_tes_1p01_jes_0p99.h5\n",
      "ICP training data: Base point nu = (1.0, -1.0, 1.0), alpha = (1.01, 0.99, 1.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/diboson_tes_1p01_jes_0p99_met_1.h5\n",
      "ICP training data: Base point nu = (1.0, -1.0, 2.0), alpha = (1.01, 0.99, 2.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/diboson_tes_1p01_jes_0p99_met_2.h5\n",
      "ICP training data: Base point nu = (1.0, 0.0, 0.0), alpha = (1.01, 1.0, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/diboson_tes_1p01.h5\n",
      "ICP training data: Base point nu = (1.0, 0.0, 1.0), alpha = (1.01, 1.0, 1.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/diboson_tes_1p01_met_1.h5\n",
      "ICP training data: Base point nu = (1.0, 0.0, 2.0), alpha = (1.01, 1.0, 2.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/diboson_tes_1p01_met_2.h5\n",
      "ICP training data: Base point nu = (1.0, 1.0, 0.0), alpha = (1.01, 1.01, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/diboson_tes_1p01_jes_1p01.h5\n",
      "ICP training data: Base point nu = (1.0, 1.0, 1.0), alpha = (1.01, 1.01, 1.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/diboson_tes_1p01_jes_1p01_met_1.h5\n",
      "ICP training data: Base point nu = (1.0, 1.0, 2.0), alpha = (1.01, 1.01, 2.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/diboson_tes_1p01_jes_1p01_met_2.h5\n",
      "ICP training data: Base point nu = (2.0, 0.0, 0.0), alpha = (1.02, 1.0, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/diboson_tes_1p02.h5\n",
      "ICP training data: Base point nu = (3.0, 0.0, 0.0), alpha = (1.03, 1.0, 0.0), file = /scratch-cbe/users/robert.schoefbeck/Higgs_uncertainty/data/lowMT_VBFJet/diboson_tes_1p03.h5\n",
      "Written ./demodir/models/ICP/ICP_diboson_lowMT_VBFJet_icp_quad_tes_jes_met.pkl\n",
      "Trained ICP with config ML.configs.icp_quad_tes_jes_met in selection lowMT_VBFJet\n",
      "ICP: lowMT_VBFJet                                 +6.0e-03*nu_tes +1.3e-02*nu_jes -3.4e-05*nu_met -9.9e-05*nu_tes*nu_tes -1.6e-04*nu_jes*nu_jes -9.2e-05*nu_met*nu_met +4.6e-05*nu_tes*nu_jes -4.5e-06*nu_tes*nu_met +5.2e-06*nu_jes*nu_met\n"
     ]
    }
   ],
   "source": [
    "config_name = \"ML.configs.icp_quad_tes_jes_met\"\n",
    "# import the training parameters in config\n",
    "config = importlib.import_module(\"%s\"%( config_name))\n",
    "for p in processes:\n",
    "    subdirs = [arg for arg in [p, selection, config_name.split('.')[-1]] if arg is not None]\n",
    "    icp_name = \"ICP_\"+\"_\".join(subdirs)\n",
    "    icp_model_directory = os.path.join( model_dir, \"ICP\" )\n",
    "    os.makedirs(icp_model_directory, exist_ok=True)\n",
    "    \n",
    "    filename = os.path.join(icp_model_directory, icp_name)+'.pkl'\n",
    "    \n",
    "\n",
    "    print (\"Training.\")\n",
    "    icp = InclusiveCrosssectionParametrization( config = config )\n",
    "\n",
    "    icp.load_training_data(datasets_hephy=datasets_hephy, training_data_dir=training_data_dir, selection=selection, process=p) \n",
    "    icp.train             (small=True, train_ratio = True, selection=None)\n",
    "\n",
    "    icp.save(filename)\n",
    "    print (\"Written %s\"%( filename ))\n",
    "    \n",
    "    print (f\"Trained ICP with config {config_name} in selection {selection}\")\n",
    "    prefix = \"ICP: \"+selection\n",
    "    print (prefix.ljust(50)+icp.__str__())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baab5f51-990e-457e-828a-8f71b7d5d88f",
   "metadata": {},
   "source": [
    "### Multiclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40ee13f7-00af-41d1-9279-f2f34afa2579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "from ML.TFMC.TFMC import TFMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6b0d5c0-8db4-46e9-81f7-36cdc41b6cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_name = \"ML.configs.tfmc_scan_do_1\"\n",
    "# import the training parameters in config\n",
    "config = importlib.import_module(\"%s\"%( config_name))\n",
    "\n",
    "# Where to store the training\n",
    "TFMC_model_directory = os.path.join(model_dir, \"TFMC\", selection, config_name.split('.')[-1])\n",
    "os.makedirs(TFMC_model_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2af12951-cc6d-4dd2-b3cf-54c20ef205c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We use this IC:\n",
      "IC: \u001b[1mlowMT_VBFJet\u001b[0m                           S/B = 0.003971  yield: htautau:    22.60 ztautau:  4120.57 ttbar:  1539.10 diboson:    32.14\n",
      "                                                           count: htautau:  1158182 ztautau:   412057 ttbar:   153883 diboson:     3213\n",
      "We use this scaler:\n",
      "Scaler: selection \u001b[1mlowMT_VBFJet\u001b[0m process (\u001b[1mnot set\u001b[0m)\n",
      "PRI_lep_pt: mean=46.312, variance=850.590\n",
      "PRI_lep_eta: mean=-0.000, variance=1.328\n",
      "PRI_lep_phi: mean=-0.002, variance=3.288\n",
      "PRI_had_pt: mean=61.323, variance=1443.225\n",
      "PRI_had_eta: mean=0.001, variance=1.393\n",
      "PRI_had_phi: mean=0.003, variance=3.287\n",
      "PRI_jet_leading_pt: mean=119.773, variance=5152.242\n",
      "PRI_jet_leading_eta: mean=-0.001, variance=3.265\n",
      "PRI_jet_leading_phi: mean=-0.002, variance=3.275\n",
      "PRI_jet_subleading_pt: mean=61.797, variance=1126.916\n",
      "PRI_jet_subleading_eta: mean=0.002, variance=4.463\n",
      "PRI_jet_subleading_phi: mean=-0.001, variance=3.246\n",
      "PRI_n_jets: mean=2.895, variance=1.162\n",
      "PRI_jet_all_pt: mean=216.515, variance=14143.631\n",
      "PRI_met: mean=57.541, variance=2185.743\n",
      "PRI_met_phi: mean=0.000, variance=3.287\n",
      "DER_mass_transverse_met_lep: mean=22.381, variance=330.112\n",
      "DER_mass_vis: mean=78.153, variance=1250.358\n",
      "DER_pt_h: mean=128.600, variance=6605.014\n",
      "DER_deltaeta_jet_jet: mean=2.348, variance=2.900\n",
      "DER_mass_jet_jet: mean=399.692, variance=228483.254\n",
      "DER_prodeta_jet_jet: mean=-0.342, variance=14.905\n",
      "DER_deltar_had_lep: mean=1.849, variance=0.487\n",
      "DER_pt_tot: mean=33.489, variance=806.460\n",
      "DER_sum_pt: mean=324.149, variance=21651.933\n",
      "DER_pt_ratio_lep_tau: mean=0.967, variance=0.622\n",
      "DER_met_phi_centrality: mean=0.834, variance=0.572\n",
      "DER_lep_eta_centrality: mean=0.446, variance=0.157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 22:14:41.869556: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/300 - Learning rate: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:   0%|                                                                             | 0/100 [00:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFMC models saved in ./demodir/models/TFMC/lowMT_VBFJet/tfmc_scan_do_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if config.use_ic:\n",
    "    from ML.IC.IC import InclusiveCrosssection\n",
    "    ic = InclusiveCrosssection.load(os.path.join(model_dir, \"IC\", \"IC_\"+selection+'.pkl'))\n",
    "    config.weight_sums = ic.weight_sums\n",
    "    print(\"We use this IC:\")\n",
    "    print(ic)\n",
    "    \n",
    "# Do we use a Scaler?\n",
    "if config.use_scaler:\n",
    "    from ML.Scaler.Scaler import Scaler \n",
    "    scaler = Scaler.load(os.path.join(model_dir, \"Scaler\", \"Scaler_\"+selection+'.pkl'))\n",
    "    config.feature_means     = scaler.feature_means\n",
    "    config.feature_variances = scaler.feature_variances\n",
    "\n",
    "    print(\"We use this scaler:\")\n",
    "    print(scaler)\n",
    "\n",
    "tfmc = TFMC(config)\n",
    "\n",
    "tfmc.load_training_data(datasets_hephy, training_data_dir, selection, n_split=100)\n",
    "\n",
    "max_batch = 1 # FIXME: -1 for full training\n",
    "\n",
    "# Determine the starting epoch\n",
    "starting_epoch = 0\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(0, config.n_epochs):\n",
    "\n",
    "    # Manually evaluate and update the learning rate\n",
    "    if hasattr(tfmc, 'lr_schedule'):  # Ensure the schedule exists\n",
    "        new_lr = tfmc.lr_schedule(epoch)\n",
    "        tfmc.optimizer.learning_rate.assign(new_lr)  # Update the optimizer's learning rate\n",
    "\n",
    "    # Print the current learning rate\n",
    "    current_lr = tf.keras.backend.get_value(tfmc.optimizer.learning_rate)  # Direct access\n",
    "    print(f\"Epoch {epoch}/{config.n_epochs} - Learning rate: {current_lr:.6f}\")\n",
    "\n",
    "    true_histograms, pred_histograms = tfmc.train_one_epoch(max_batch=max_batch, accumulate_histograms=(epoch%1==0))\n",
    "    tfmc.save(TFMC_model_directory, epoch)  # Save model and config after each epoch\n",
    "\n",
    "    #if true_histograms is not None and pred_histograms is not None:\n",
    "    #    # Plot convergence\n",
    "    #    tfmc.plot_convergence_root(\n",
    "    #        true_histograms,\n",
    "    #        pred_histograms,\n",
    "    #        epoch,\n",
    "    #        plot_directory,\n",
    "    #        data_structure.feature_names, \n",
    "    #    )\n",
    "\n",
    "    break\n",
    "\n",
    "print(f\"TFMC models saved in {TFMC_model_directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aff2937-113e-416c-9bc8-79a05e8fa972",
   "metadata": {},
   "source": [
    "### Calibrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "feba95e8-cd20-4a41-b7f4-81efa8e61f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FIXME: not sure how is the calibrator trained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366c1039-5259-4afb-8987-f2628598d49b",
   "metadata": {},
   "source": [
    "### PNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c711c3c-e134-4dc5-bd8f-acf9b61c97b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ML.PNN.PNN import PNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bce2165a-94f6-43ae-a7ea-01b8367f284f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We use this ICP: ICP_htautau_lowMT_VBFJet_icp_quad_tes_jes_met.pkl\n",
      "+6.0e-03*nu_tes +1.3e-02*nu_jes -3.4e-05*nu_met -9.9e-05*nu_tes*nu_tes -1.6e-04*nu_jes*nu_jes -9.2e-05*nu_met*nu_met +4.6e-05*nu_tes*nu_jes -4.5e-06*nu_tes*nu_met +5.2e-06*nu_jes*nu_met\n",
      "We use this scaler: Scaler_htautau_lowMT_VBFJet.pkl\n",
      "Scaler: selection \u001b[1mlowMT_VBFJet\u001b[0m process (\u001b[1mhtautau\u001b[0m)\n",
      "PRI_lep_pt: mean=47.784, variance=934.071\n",
      "PRI_lep_eta: mean=0.000, variance=1.262\n",
      "PRI_lep_phi: mean=-0.001, variance=3.288\n",
      "PRI_had_pt: mean=64.702, variance=1609.351\n",
      "PRI_had_eta: mean=0.001, variance=1.324\n",
      "PRI_had_phi: mean=0.003, variance=3.285\n",
      "PRI_jet_leading_pt: mean=127.257, variance=5997.741\n",
      "PRI_jet_leading_eta: mean=-0.001, variance=3.695\n",
      "PRI_jet_leading_phi: mean=-0.001, variance=3.269\n",
      "PRI_jet_subleading_pt: mean=63.424, variance=1245.298\n",
      "PRI_jet_subleading_eta: mean=0.000, variance=4.870\n",
      "PRI_jet_subleading_phi: mean=-0.002, variance=3.229\n",
      "PRI_n_jets: mean=2.893, variance=1.149\n",
      "PRI_jet_all_pt: mean=225.778, variance=15460.502\n",
      "PRI_met: mean=61.891, variance=2510.637\n",
      "PRI_met_phi: mean=-0.000, variance=3.285\n",
      "DER_mass_transverse_met_lep: mean=21.215, variance=301.869\n",
      "DER_mass_vis: mean=78.929, variance=695.320\n",
      "DER_pt_h: mean=138.602, variance=7623.948\n",
      "DER_deltaeta_jet_jet: mean=2.610, variance=3.283\n",
      "DER_mass_jet_jet: mean=476.071, variance=296304.926\n",
      "DER_prodeta_jet_jet: mean=-0.767, variance=17.636\n",
      "DER_deltar_had_lep: mean=1.843, variance=0.458\n",
      "DER_pt_tot: mean=33.763, variance=823.468\n",
      "DER_sum_pt: mean=338.264, variance=23649.631\n",
      "DER_pt_ratio_lep_tau: mean=0.966, variance=0.686\n",
      "DER_met_phi_centrality: mean=0.907, variance=0.480\n",
      "DER_lep_eta_centrality: mean=0.488, variance=0.161\n",
      "We use this ICP: ICP_ztautau_lowMT_VBFJet_icp_quad_tes_jes_met.pkl\n",
      "+6.0e-03*nu_tes +1.3e-02*nu_jes -3.4e-05*nu_met -9.9e-05*nu_tes*nu_tes -1.6e-04*nu_jes*nu_jes -9.2e-05*nu_met*nu_met +4.6e-05*nu_tes*nu_jes -4.5e-06*nu_tes*nu_met +5.2e-06*nu_jes*nu_met\n",
      "We use this scaler: Scaler_ztautau_lowMT_VBFJet.pkl\n",
      "Scaler: selection \u001b[1mlowMT_VBFJet\u001b[0m process (\u001b[1mztautau\u001b[0m)\n",
      "PRI_lep_pt: mean=39.566, variance=469.536\n",
      "PRI_lep_eta: mean=-0.002, variance=1.515\n",
      "PRI_lep_phi: mean=-0.003, variance=3.288\n",
      "PRI_had_pt: mean=51.492, variance=767.799\n",
      "PRI_had_eta: mean=-0.001, variance=1.536\n",
      "PRI_had_phi: mean=0.005, variance=3.294\n",
      "PRI_jet_leading_pt: mean=101.049, variance=2794.791\n",
      "PRI_jet_leading_eta: mean=-0.002, variance=2.492\n",
      "PRI_jet_leading_phi: mean=-0.001, variance=3.289\n",
      "PRI_jet_subleading_pt: mean=53.996, variance=654.296\n",
      "PRI_jet_subleading_eta: mean=0.003, variance=4.014\n",
      "PRI_jet_subleading_phi: mean=0.002, variance=3.280\n",
      "PRI_n_jets: mean=2.632, variance=0.735\n",
      "PRI_jet_all_pt: mean=177.241, variance=7082.650\n",
      "PRI_met: mean=46.165, variance=1238.804\n",
      "PRI_met_phi: mean=-0.000, variance=3.293\n",
      "DER_mass_transverse_met_lep: mean=18.808, variance=242.323\n",
      "DER_mass_vis: mean=62.764, variance=485.544\n",
      "DER_pt_h: mean=110.573, variance=3816.681\n",
      "DER_deltaeta_jet_jet: mean=1.941, variance=1.743\n",
      "DER_mass_jet_jet: mean=243.677, variance=54843.194\n",
      "DER_prodeta_jet_jet: mean=0.498, variance=9.240\n",
      "DER_deltar_had_lep: mean=1.704, variance=0.397\n",
      "DER_pt_tot: mean=27.165, variance=457.734\n",
      "DER_sum_pt: mean=268.299, variance=10949.438\n",
      "DER_pt_ratio_lep_tau: mean=0.928, variance=0.422\n",
      "DER_met_phi_centrality: mean=0.870, variance=0.472\n",
      "DER_lep_eta_centrality: mean=0.372, variance=0.139\n",
      "We use this ICP: ICP_ttbar_lowMT_VBFJet_icp_quad_tes_jes_met.pkl\n",
      "+6.0e-03*nu_tes +1.3e-02*nu_jes -3.4e-05*nu_met -9.9e-05*nu_tes*nu_tes -1.6e-04*nu_jes*nu_jes -9.2e-05*nu_met*nu_met +4.6e-05*nu_tes*nu_jes -4.5e-06*nu_tes*nu_met +5.2e-06*nu_jes*nu_met\n",
      "We use this scaler: Scaler_ttbar_lowMT_VBFJet.pkl\n",
      "Scaler: selection \u001b[1mlowMT_VBFJet\u001b[0m process (\u001b[1mttbar\u001b[0m)\n",
      "PRI_lep_pt: mean=53.159, variance=1044.421\n",
      "PRI_lep_eta: mean=-0.002, variance=1.323\n",
      "PRI_lep_phi: mean=-0.006, variance=3.294\n",
      "PRI_had_pt: mean=62.264, variance=1643.271\n",
      "PRI_had_eta: mean=0.002, variance=1.519\n",
      "PRI_had_phi: mean=0.002, variance=3.280\n",
      "PRI_jet_leading_pt: mean=113.748, variance=3677.991\n",
      "PRI_jet_leading_eta: mean=0.000, variance=2.105\n",
      "PRI_jet_leading_phi: mean=-0.004, variance=3.286\n",
      "PRI_jet_subleading_pt: mean=70.515, variance=1240.345\n",
      "PRI_jet_subleading_eta: mean=0.007, variance=2.618\n",
      "PRI_jet_subleading_phi: mean=-0.004, variance=3.286\n",
      "PRI_n_jets: mean=3.611, variance=1.704\n",
      "PRI_jet_all_pt: mean=252.284, variance=17048.546\n",
      "PRI_met: mean=55.356, variance=1767.396\n",
      "PRI_met_phi: mean=0.005, variance=3.291\n",
      "DER_mass_transverse_met_lep: mean=40.492, variance=400.664\n",
      "DER_mass_vis: mean=113.021, variance=5512.091\n",
      "DER_pt_h: mean=101.937, variance=4052.666\n",
      "DER_deltaeta_jet_jet: mean=1.478, variance=1.403\n",
      "DER_mass_jet_jet: mean=246.216, variance=53366.434\n",
      "DER_prodeta_jet_jet: mean=0.568, variance=5.499\n",
      "DER_deltar_had_lep: mean=2.270, variance=0.700\n",
      "DER_pt_tot: mean=48.416, variance=1284.531\n",
      "DER_sum_pt: mean=367.707, variance=23455.102\n",
      "DER_pt_ratio_lep_tau: mean=1.074, variance=0.657\n",
      "DER_met_phi_centrality: mean=0.193, variance=1.065\n",
      "DER_lep_eta_centrality: mean=0.335, variance=0.141\n",
      "We use this ICP: ICP_diboson_lowMT_VBFJet_icp_quad_tes_jes_met.pkl\n",
      "+6.0e-03*nu_tes +1.3e-02*nu_jes -3.4e-05*nu_met -9.9e-05*nu_tes*nu_tes -1.6e-04*nu_jes*nu_jes -9.2e-05*nu_met*nu_met +4.6e-05*nu_tes*nu_jes -4.5e-06*nu_tes*nu_met +5.2e-06*nu_jes*nu_met\n",
      "We use this scaler: Scaler_diboson_lowMT_VBFJet.pkl\n",
      "Scaler: selection \u001b[1mlowMT_VBFJet\u001b[0m process (\u001b[1mdiboson\u001b[0m)\n",
      "PRI_lep_pt: mean=52.322, variance=1401.210\n",
      "PRI_lep_eta: mean=0.015, variance=1.606\n",
      "PRI_lep_phi: mean=0.062, variance=3.300\n",
      "PRI_had_pt: mean=58.732, variance=1956.844\n",
      "PRI_had_eta: mean=-0.003, variance=1.767\n",
      "PRI_had_phi: mean=-0.002, variance=3.280\n",
      "PRI_jet_leading_pt: mean=111.085, variance=5805.496\n",
      "PRI_jet_leading_eta: mean=0.019, variance=2.652\n",
      "PRI_jet_leading_phi: mean=-0.018, variance=3.203\n",
      "PRI_jet_subleading_pt: mean=57.652, variance=1130.582\n",
      "PRI_jet_subleading_eta: mean=0.033, variance=3.621\n",
      "PRI_jet_subleading_phi: mean=0.008, variance=3.396\n",
      "PRI_n_jets: mean=2.835, variance=1.030\n",
      "PRI_jet_all_pt: mean=199.712, variance=14062.440\n",
      "PRI_met: mean=53.006, variance=2862.308\n",
      "PRI_met_phi: mean=-0.037, variance=3.270\n",
      "DER_mass_transverse_met_lep: mean=32.788, variance=444.379\n",
      "DER_mass_vis: mean=102.081, variance=6088.203\n",
      "DER_pt_h: mean=111.582, variance=6951.246\n",
      "DER_deltaeta_jet_jet: mean=1.566, variance=1.588\n",
      "DER_mass_jet_jet: mean=223.567, variance=50248.591\n",
      "DER_prodeta_jet_jet: mean=1.116, variance=10.134\n",
      "DER_deltar_had_lep: mean=2.103, variance=0.740\n",
      "DER_pt_tot: mean=30.966, variance=623.456\n",
      "DER_sum_pt: mean=310.765, variance=23004.736\n",
      "DER_pt_ratio_lep_tau: mean=1.133, variance=0.906\n",
      "DER_met_phi_centrality: mean=0.438, variance=0.977\n",
      "DER_lep_eta_centrality: mean=0.311, variance=0.141\n",
      "Epoch 0/200 - Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNN models saved in ./demodir/models/PNN/diboson/lowMT_VBFJet/ML.configs.pnn_quad_tes_jes_met\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "config_name = \"ML.configs.pnn_quad_tes_jes_met\"\n",
    "# import the training parameters in config\n",
    "config = importlib.import_module(\"%s\"%( config_name))\n",
    "\n",
    "for p in processes:\n",
    "    subdirs= [arg for arg in [p, selection] if arg is not None]\n",
    "\n",
    "    # Do we use ICP?\n",
    "    if config.icp is not None:\n",
    "        from ML.ICP.ICP import InclusiveCrosssectionParametrization\n",
    "        icp_name = \"ICP_\"+\"_\".join(subdirs)+\"_\"+config.icp+\".pkl\"\n",
    "        icp = InclusiveCrosssectionParametrization.load(os.path.join(model_dir, \"ICP\", icp_name))\n",
    "        config.icp_predictor = icp.get_predictor()\n",
    "        print(\"We use this ICP:\",icp_name)\n",
    "        print(icp)\n",
    "    \n",
    "    # Do we use a Scaler?\n",
    "    if config.use_scaler:\n",
    "        from ML.Scaler.Scaler import Scaler\n",
    "        scaler_name = \"Scaler_\"+\"_\".join(subdirs)+'.pkl'\n",
    "        scaler = Scaler.load(os.path.join(model_dir, \"Scaler\", scaler_name))\n",
    "        config.feature_means     = scaler.feature_means\n",
    "        config.feature_variances = scaler.feature_variances\n",
    "    \n",
    "        print(\"We use this scaler:\", scaler_name)\n",
    "        print(scaler)\n",
    "    \n",
    "    # Where to store the training\n",
    "    pnn_model_directory = os.path.join(model_dir, \"PNN\", *subdirs,  config_name)\n",
    "    os.makedirs(pnn_model_directory, exist_ok=True)\n",
    "\n",
    "# Initialize model\n",
    "pnn = PNN(config)\n",
    "\n",
    "# Initialize for training\n",
    "pnn.load_training_data(datasets_hephy=datasets_hephy, training_data_dir=training_data_dir, process=p, selection=selection, n_split=100)\n",
    "\n",
    "max_batch = 1 #if args.small else -1\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(0, config.n_epochs):\n",
    "\n",
    "    # Manually evaluate and update the learning rate\n",
    "    if hasattr(pnn, 'lr_schedule'):  # Ensure the schedule exists\n",
    "        new_lr = pnn.lr_schedule(epoch)\n",
    "        pnn.optimizer.learning_rate.assign(new_lr)  # Update the optimizer's learning rate\n",
    "  \n",
    "    # Print the current learning rate\n",
    "    current_lr = tf.keras.backend.get_value(pnn.optimizer.learning_rate)  # Direct access\n",
    "    print(f\"Epoch {epoch}/{config.n_epochs} - Learning rate: {current_lr:.6f}\")\n",
    "\n",
    "    true_histograms, pred_histograms = pnn.train_one_epoch(max_batch=max_batch, accumulate_histograms=(epoch%1==0), rebin=1)\n",
    "    pnn.save(pnn_model_directory, epoch)  # Save model and config after each epoch\n",
    "\n",
    "    break\n",
    "\n",
    "\n",
    "print(f\"PNN models saved in {pnn_model_directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3901556-e82a-42b9-bbc5-1bea103f4118",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76c55bc-b24f-45a9-bee6-4c1fc2910bd0",
   "metadata": {},
   "source": [
    "For the predictions performed below, the fully trained model provided in `./models` are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84615050-cf81-4d31-bcf3-281b7c765183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "from Workflow.Inference import Inference\n",
    "from common.likelihoodFit import likelihoodFit\n",
    "from common.intervalFinder import intervalFinder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd94622a-f003-4540-b9b9-a074a7801b46",
   "metadata": {},
   "source": [
    "### Load test dataset and config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897954cf-d9de-49af-b4c2-83ac2f936f3b",
   "metadata": {},
   "source": [
    "A config file `./configs/config_submission.yaml` is used to control the path of the ML models. Please find the detailed information in the README of the GitHub repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52e1245b-961e-4b17-bfc8-005c868e62ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_h5_to_test_set(h5_file_path):\n",
    "    with h5py.File(h5_file_path, \"r\") as hf:\n",
    "        full_data = hf[\"data\"][:]  # (N, 30)\n",
    "    test_data = pd.DataFrame(full_data[:, :28])  # (N, 28)\n",
    "    test_weights = full_data[:, 28]  # (N,)\n",
    "    test_set = {\n",
    "        \"data\": test_data,\n",
    "        \"weights\": test_weights\n",
    "    }\n",
    "    return test_set\n",
    "\n",
    "def loadConfig(config_path):\n",
    "    if config_path.endswith(\".pkl\"):\n",
    "        use_yaml = False\n",
    "    else:\n",
    "        try:\n",
    "            import yaml\n",
    "            use_yaml = True\n",
    "        except:\n",
    "            import pickle\n",
    "            use_yaml = False\n",
    "            config_path = config_path.replace(\".yaml\", \".pkl\")\n",
    "\n",
    "    assert os.path.exists(config_path), \"Config does not exist: {}\".format(config_path)\n",
    "\n",
    "    if use_yaml:\n",
    "        with open(config_path) as f:\n",
    "            cfg = yaml.safe_load(f)\n",
    "    else:\n",
    "        with open(config_path) as f:\n",
    "            cfg = pickle.load(f, 'rb')\n",
    "\n",
    "    for task in cfg[\"Tasks\"]:\n",
    "        for selection in cfg[\"Selections\"]:\n",
    "            for item in [\"calibration\", \"icp_file\", \"model_path\"]:\n",
    "                if item in cfg[task][selection]:\n",
    "                    cfg[task][selection][item] = cfg[task][selection][item]\n",
    "\n",
    "    if \"Poisson\" in cfg:\n",
    "        for sel in cfg[\"Poisson\"].keys():\n",
    "            if 'model_path' in cfg[\"Poisson\"][sel]:\n",
    "                cfg[\"Poisson\"][sel][\"model_path\"] = cfg[\"Poisson\"][sel][\"model_path\"]\n",
    "            cfg[\"Poisson\"][sel][\"IC\"] = cfg[\"Poisson\"][sel][\"IC\"]\n",
    "            for process in cfg[\"Poisson\"][sel][\"ICP\"].keys():\n",
    "                cfg[\"Poisson\"][sel][\"ICP\"][process] = cfg[\"Poisson\"][sel][\"ICP\"][process]\n",
    "    \n",
    "    cfg['tmp_path'] = f\"data/tmp_data\"\n",
    "\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b502d1fa-4f10-43f9-a1a4-01a6e5cc5bd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset_path = \"/eos/vbc/group/mlearning/data/Higgs_uncertainty/input_data/split_train_dataset/processed_data/pseudo_experiments_with_true_labels_mu_2/set_2.0_pseudo_exp_10.h5\"\n",
    "test_dataset = load_h5_to_test_set(test_dataset_path)\n",
    "\n",
    "predict_config = \"configs/config_submission.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8342dd32-0032-4306-9c4d-835333904478",
   "metadata": {},
   "source": [
    "### Pre-save information for training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3d54e6-7163-4601-9ec9-d18184ae8953",
   "metadata": {},
   "source": [
    "The prediction requires information from the training dataset for the inclusive cross section term. To reduce the runtime of the prediction steps, we pre-save the ML output for the training data, and save the cubic spline interpolation (CSI) for inclusive cross section and poisson terms. \n",
    "\n",
    "The pre-saved files are all data with the fully trained ML models are availible in `data/tmp_data`. Those files will be used later in the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01963aa6-ea46-405b-8e80-7bab6563ed8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   0%|          | 0/100 [00:02<?, ?it/s]\n",
      "Processing batches:   0%|          | 0/100 [00:02<?, ?it/s]\n",
      "Processing batches:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Processing batches:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Processing batches:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Processing batches:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Processing batches:   1%|          | 1/100 [00:00<00:14,  6.87it/s]\n",
      "Processing batches:   1%|          | 1/100 [00:00<00:11,  8.87it/s]\n",
      "Processing batches:   1%|          | 1/100 [00:04<08:05,  4.90s/it]\n",
      "Warning! Temporary file demodir/tmp_data/nominal_lowMT_VBFJet.h5 exists. It will be overwritten.\n",
      "Processing batches:   0%|          | 0/100 [00:02<?, ?it/s]\n",
      "Warning! Temporary file demodir/tmp_data/TrainingData_lowMT_VBFJet.h5 exists. It will be overwritten.\n",
      "Processing batches:   0%|          | 0/100 [00:02<?, ?it/s]\n",
      "CSI lowMT_VBFJet htautau: 100%|| 2/2 [00:22<00:00, 11.29s/it]\n",
      "Warning! Temporary file demodir/tmp_data/nominal_lowMT_noVBFJet_ptH100.h5 exists. It will be overwritten.\n",
      "Processing batches:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Warning! Temporary file demodir/tmp_data/TrainingData_lowMT_noVBFJet_ptH100.h5 exists. It will be overwritten.\n",
      "Processing batches:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "CSI lowMT_noVBFJet_ptH100 htautau: 100%|| 1/1 [00:06<00:00,  6.06s/it]\n",
      "Warning! Temporary file demodir/tmp_data/nominal_highMT_VBFJet.h5 exists. It will be overwritten.\n",
      "Processing batches:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Warning! Temporary file demodir/tmp_data/TrainingData_highMT_VBFJet.h5 exists. It will be overwritten.\n",
      "Processing batches:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "CSI highMT_VBFJet htautau: 100%|| 1/1 [00:03<00:00,  3.30s/it]\n",
      "Processing batches:   1%|          | 1/100 [00:00<00:14,  6.98it/s]\n",
      "Processing batches:   1%|          | 1/100 [00:00<00:11,  8.57it/s]\n",
      "Processing batches:   1%|          | 1/100 [00:04<08:05,  4.91s/it]\n",
      "Warning! Temporary file demodir/tmp_data/nominal_lowMT_VBFJet.h5 exists. It will be overwritten.\n",
      "Processing batches:   0%|          | 0/100 [00:02<?, ?it/s]\n",
      "Warning! Temporary file demodir/tmp_data/TrainingData_lowMT_VBFJet.h5 exists. It will be overwritten.\n",
      "Processing batches:   0%|          | 0/100 [00:02<?, ?it/s]\n",
      "CSI lowMT_VBFJet ztautau: 100%|| 2/2 [00:22<00:00, 11.19s/it]\n",
      "Warning! Temporary file demodir/tmp_data/nominal_lowMT_noVBFJet_ptH100.h5 exists. It will be overwritten.\n",
      "Processing batches:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Warning! Temporary file demodir/tmp_data/TrainingData_lowMT_noVBFJet_ptH100.h5 exists. It will be overwritten.\n",
      "Processing batches:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "CSI lowMT_noVBFJet_ptH100 ztautau: 100%|| 1/1 [00:06<00:00,  6.04s/it]\n",
      "Warning! Temporary file demodir/tmp_data/nominal_highMT_VBFJet.h5 exists. It will be overwritten.\n",
      "Processing batches:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Warning! Temporary file demodir/tmp_data/TrainingData_highMT_VBFJet.h5 exists. It will be overwritten.\n",
      "Processing batches:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "CSI highMT_VBFJet ztautau: 100%|| 1/1 [00:03<00:00,  3.32s/it]\n",
      "Processing batches:   1%|          | 1/100 [00:00<00:13,  7.24it/s]\n",
      "Processing batches:   1%|          | 1/100 [00:00<00:12,  8.05it/s]\n",
      "Processing batches:   1%|          | 1/100 [00:04<07:59,  4.84s/it]\n",
      "Warning! Temporary file demodir/tmp_data/nominal_lowMT_VBFJet.h5 exists. It will be overwritten.\n",
      "Processing batches:   0%|          | 0/100 [00:02<?, ?it/s]\n",
      "Warning! Temporary file demodir/tmp_data/TrainingData_lowMT_VBFJet.h5 exists. It will be overwritten.\n",
      "Processing batches:   0%|          | 0/100 [00:02<?, ?it/s]\n",
      "CSI lowMT_VBFJet ttbar: 100%|| 2/2 [00:22<00:00, 11.22s/it]\n",
      "Warning! Temporary file demodir/tmp_data/nominal_lowMT_noVBFJet_ptH100.h5 exists. It will be overwritten.\n",
      "Processing batches:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Warning! Temporary file demodir/tmp_data/TrainingData_lowMT_noVBFJet_ptH100.h5 exists. It will be overwritten.\n",
      "Processing batches:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "CSI lowMT_noVBFJet_ptH100 ttbar: 100%|| 1/1 [00:06<00:00,  6.01s/it]\n",
      "Warning! Temporary file demodir/tmp_data/nominal_highMT_VBFJet.h5 exists. It will be overwritten.\n",
      "Processing batches:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Warning! Temporary file demodir/tmp_data/TrainingData_highMT_VBFJet.h5 exists. It will be overwritten.\n",
      "Processing batches:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "CSI highMT_VBFJet ttbar: 100%|| 1/1 [00:03<00:00,  3.23s/it]\n",
      "Processing batches:   1%|          | 1/100 [00:00<00:13,  7.12it/s]\n",
      "Processing batches:   1%|          | 1/100 [00:00<00:11,  8.46it/s]\n",
      "Processing batches:   1%|          | 1/100 [00:04<08:01,  4.87s/it]\n",
      "Warning! Temporary file demodir/tmp_data/nominal_lowMT_VBFJet.h5 exists. It will be overwritten.\n",
      "Processing batches:   0%|          | 0/100 [00:02<?, ?it/s]\n",
      "Warning! Temporary file demodir/tmp_data/TrainingData_lowMT_VBFJet.h5 exists. It will be overwritten.\n",
      "Processing batches:   0%|          | 0/100 [00:02<?, ?it/s]\n",
      "CSI lowMT_VBFJet diboson: 100%|| 2/2 [00:22<00:00, 11.14s/it]\n",
      "Warning! Temporary file demodir/tmp_data/nominal_lowMT_noVBFJet_ptH100.h5 exists. It will be overwritten.\n",
      "Processing batches:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Warning! Temporary file demodir/tmp_data/TrainingData_lowMT_noVBFJet_ptH100.h5 exists. It will be overwritten.\n",
      "Processing batches:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "CSI lowMT_noVBFJet_ptH100 diboson: 100%|| 1/1 [00:06<00:00,  6.23s/it]\n",
      "Warning! Temporary file demodir/tmp_data/nominal_highMT_VBFJet.h5 exists. It will be overwritten.\n",
      "Processing batches:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Warning! Temporary file demodir/tmp_data/TrainingData_highMT_VBFJet.h5 exists. It will be overwritten.\n",
      "Processing batches:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "CSI highMT_VBFJet diboson: 100%|| 1/1 [00:03<00:00,  3.34s/it]\n",
      "Processing batches:   1%|          | 1/100 [00:00<00:13,  7.39it/s]\n",
      "Processing batches:   1%|          | 1/100 [00:00<00:12,  7.62it/s]\n",
      "Processing batches:   1%|          | 1/100 [00:04<08:03,  4.88s/it]\n"
     ]
    }
   ],
   "source": [
    "cfg = loadConfig(predict_config)\n",
    "cfg['training_data_dir'] = training_data_dir\n",
    "infer = Inference(cfg, small=True, overwrite=True, toy_origin=\"config\", toy_path=None, toy_from_memory=None)\n",
    "infer.cfg[\"CSI\"][\"save\"] = False\n",
    "cfg['tmp_path'] = \"demodir/tmp_data\"\n",
    "infer.save(restrict_csis = [])\n",
    "for p in processes:\n",
    "    infer = Inference(cfg, small=True, overwrite=True, toy_origin=\"config\", toy_path=None, toy_from_memory=None)\n",
    "    infer.cfg[\"CSI\"][\"save\"] = True\n",
    "    cfg['tmp_path'] = \"demodir/tmp_data\"\n",
    "    infer.save(restrict_csis = [p])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d51e6f-63b7-4f3d-b8e0-ba648dd9a4dc",
   "metadata": {},
   "source": [
    "### Construct the likelyhood function and extract the interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54b2d311-1cfd-4c63-8595-3720c69e5459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                Migrad                                   \n",
      "\n",
      " FCN = -5.977e+04                               Nfcn = 415              \n",
      " EDM = 2.73e-06 (Goal: 0.0001)                time = 6.4 sec            \n",
      "\n",
      "          Valid Minimum              Below EDM threshold (goal x 10)    \n",
      "\n",
      "     SOME parameters at limit                Below call limit           \n",
      "\n",
      "             Hesse ok                      Covariance accurate          \n",
      "\n",
      "\n",
      "    Name          Value    Hesse Err  Minos Err-  Minos Err+  Limit-   Limit+   Fixed \n",
      "\n",
      " 0  mu            361.2       1.3                                0                    \n",
      " 1  nu_bkg        -5.7        0.7                               -10      10           \n",
      " 2  nu_tt        10.0000    0.0005                              -10      10           \n",
      " 3  nu_diboson    -2.8        0.4                               -4        4           \n",
      " 4  nu_tes      -10.0000    0.0004                              -10      10           \n",
      " 5  nu_jes        2.25       0.04                               -10      10           \n",
      " 6  nu_met       5.0000     0.0012                               0        5           \n",
      "\n",
      "\n",
      "                      mu      nu_bkg       nu_tt  nu_diboson      nu_tes      nu_jes      nu_met \n",
      "\n",
      "         mu         1.64        -0.5  18.3908e-9       -0.05  10.1286e-9     -0.0023  42.9834e-9 \n",
      "     nu_bkg         -0.5       0.438 -12.7410e-9        0.00  11.0019e-9      0.0022  -9.5622e-9 \n",
      "      nu_tt   18.3908e-9 -12.7410e-9    1.08e-12  -2.3798e-9           0   367.8e-12          -0 \n",
      " nu_diboson        -0.05        0.00  -2.3798e-9       0.129  -3.8469e-9      0.0008  -9.4851e-9 \n",
      "     nu_tes   10.1286e-9  11.0019e-9           0  -3.8469e-9    4.86e-13   559.6e-12          -0 \n",
      "     nu_jes      -0.0023      0.0022   367.8e-12      0.0008   559.6e-12     0.00153   461.8e-12 \n",
      "     nu_met   42.9834e-9  -9.5622e-9          -0  -9.4851e-9          -0   461.8e-12    3.43e-12 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "offset = 0.0\n",
    "inflate = 1.045\n",
    "\n",
    "infer = Inference(cfg=cfg, small=False, overwrite=False, toy_origin=\"memory\", toy_path=None, toy_from_memory=None)\n",
    "infer.ignore_loading_check()\n",
    "\n",
    "# Initialize inference object\n",
    "infer.setToyFromMemory(test_dataset)\n",
    "infer._dcr_cache = {}\n",
    "\n",
    "# Define likelihood function\n",
    "likelihood_function = lambda mu, nu_bkg, nu_tt, nu_diboson, nu_tes, nu_jes, nu_met: \\\n",
    "    infer.predict(mu=mu, nu_bkg=nu_bkg, nu_tt=nu_tt, nu_diboson=nu_diboson, \\\n",
    "    nu_tes=nu_tes, nu_jes=nu_jes, nu_met=nu_met, \\\n",
    "    asimov_mu=None, \\\n",
    "    asimov_nu_bkg=None, \\\n",
    "    asimov_nu_tt=None, \\\n",
    "    asimov_nu_diboson=None)\n",
    "\n",
    "# Perform global fit\n",
    "fit = likelihoodFit(likelihood_function)\n",
    "fit.parameterBoundaries[\"mu\"] = (0, None)\n",
    "q_mle, parameters_mle, cov, limits = fit.fit(start_mu=1.0)\n",
    "\n",
    "mu_mle = parameters_mle[\"mu\"]\n",
    "delta_mu = np.sqrt(cov[\"mu\", \"mu\"])\n",
    "p16 = mu_mle - delta_mu\n",
    "p84 = mu_mle + delta_mu\n",
    "\n",
    "# Now do NON-PROFILED scan\n",
    "Npoints = 21\n",
    "mumin = min(mu_mle - 3*delta_mu, mu_mle-0.5) # if delta_mu is too small, scan from mu-0.5 to mu+0.5\n",
    "mumax = max(mu_mle + 3*delta_mu, mu_mle+0.5) # if delta_mu is too small, scan from mu-0.5 to mu+0.5\n",
    "\n",
    "# Now go to MLE point and only evaluate mu\n",
    "deltaQ = []\n",
    "muPoints = [mumin+i*(mumax-mumin)/Npoints for i in range(Npoints)]\n",
    "\n",
    "for i, mu in enumerate(muPoints):\n",
    "    q = likelihood_function(mu=mu, nu_bkg=parameters_mle[\"nu_bkg\"], nu_tt=parameters_mle[\"nu_tt\"], nu_diboson=parameters_mle[\"nu_diboson\"], nu_tes=parameters_mle[\"nu_tes\"], nu_jes=parameters_mle[\"nu_jes\"], nu_met=parameters_mle[\"nu_met\"])\n",
    "    deltaQ.append(q-q_mle)\n",
    "\n",
    "# Interval finder interpolates and returns crossing points\n",
    "# if a boundary is below best fit mu, it is the lower boundary, if above it is the upper\n",
    "\n",
    "intFinder = intervalFinder(muPoints, deltaQ, 1.0)\n",
    "boundaries = intFinder.getInterval()\n",
    "for b in boundaries:\n",
    "    if b < mu_mle:\n",
    "        p16 = b\n",
    "    if b > mu_mle:\n",
    "        p84 = b\n",
    "\n",
    "# inflate and offset\n",
    "\n",
    "p16 = mu_mle - inflate*(mu_mle-p16) + offset\n",
    "p84 = mu_mle + inflate*(p84-mu_mle) + offset\n",
    "mu_mle = mu_mle + offset\n",
    "\n",
    "# Check mu boundaries\n",
    "if p16 < 0.1:\n",
    "    p16 = 0.09\n",
    "if p84 > 3.0:\n",
    "    p84 = 3.01\n",
    "\n",
    "delta_mu = (p84-p16)/2\n",
    "\n",
    "results = {\n",
    "            \"mu_hat\": mu_mle,\n",
    "            \"delta_mu_hat\": delta_mu,\n",
    "            \"p16\": p16,\n",
    "            \"p84\": p84,\n",
    "            \"nu_bkg\": parameters_mle[\"nu_bkg\"],\n",
    "            \"nu_tt\":  parameters_mle[\"nu_tt\"],\n",
    "            \"nu_diboson\": parameters_mle[\"nu_diboson\"],\n",
    "            \"nu_tes\": parameters_mle[\"nu_tes\"],\n",
    "            \"nu_jes\": parameters_mle[\"nu_jes\"],\n",
    "            \"nu_met\": parameters_mle[\"nu_met\"],\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26987f9c-7f8b-4458-a53c-912591c40ce8",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca04284c-dbf4-4579-aaf2-b514ddd8f11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mu_hat': 361.1596758617736, 'delta_mu_hat': -178.28152296167193, 'p16': 359.57304592334384, 'p84': 3.01, 'nu_bkg': -5.711534845999731, 'nu_tt': 9.999999999482512, 'nu_diboson': -2.84210418098054, 'nu_tes': -9.99999999972082, 'nu_jes': 2.2470104072546913, 'nu_met': 4.99999999926586}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uncertainty_challenge_new",
   "language": "python",
   "name": "uncertainty_challenge_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
